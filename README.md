# BraTS Brain Tumor Segmentation Web App

## INSTANT-ODC AI Hackathon 2026

A production-ready web application for Brain Tumor Segmentation using deep learning. Upload 4 MRI modalities and get instant 3D visualization of tumor regions.

![BraTS Segmentation](https://img.shields.io/badge/BraTS-Segmentation-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green)
![React](https://img.shields.io/badge/React-18.2-blue)

---

## ğŸ“‹ Project Overview

This application provides automated brain tumor segmentation from multimodal MRI scans using a ResUNet2D deep learning model trained on BraTS (Brain Tumor Segmentation) challenge data.

### Features

- **4-Channel MRI Input**: Supports FLAIR, T1, T1ce, and T2 modalities
- **Real-time Inference**: Fast slice-wise segmentation using GPU/CPU
- **Interactive 3D Visualization**: Plotly-based 3D scatter plot with rotation, zoom, and pan
- **Tumor Statistics**: Volume quantification for each tumor region
- **Professional UI**: Modern medical-grade interface with drag & drop upload

### Tumor Classes

| Class | Label | Color | Description |
|-------|-------|-------|-------------|
| 1 | Necrotic Core | ğŸ”´ Red | Dead tumor tissue |
| 2 | Edema | ğŸŸ¢ Green | Swelling around tumor |
| 4 | Enhancing Tumor | ğŸŸ¡ Gold | Active tumor with contrast enhancement |

---

## ğŸ§  Inference Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INFERENCE PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. LOAD NIfTI FILES                                           â”‚
â”‚     â”œâ”€â”€ FLAIR (.nii / .nii.gz)                                 â”‚
â”‚     â”œâ”€â”€ T1                                                      â”‚
â”‚     â”œâ”€â”€ T1ce (contrast-enhanced)                               â”‚
â”‚     â””â”€â”€ T2                                                      â”‚
â”‚                                                                 â”‚
â”‚  2. PREPROCESSING                                               â”‚
â”‚     â”œâ”€â”€ Smart NIfTI loading (handle orientations)              â”‚
â”‚     â”œâ”€â”€ Create brain mask (non-zero voxels)                    â”‚
â”‚     â””â”€â”€ BraTS normalization (z-score on brain region)          â”‚
â”‚                                                                 â”‚
â”‚  3. SLICE-WISE INFERENCE                                        â”‚
â”‚     â”œâ”€â”€ For each axial slice:                                  â”‚
â”‚     â”‚   â”œâ”€â”€ Resize to 240Ã—240                                  â”‚
â”‚     â”‚   â”œâ”€â”€ Forward pass through ResUNet2D                     â”‚
â”‚     â”‚   â”œâ”€â”€ Argmax for class prediction                        â”‚
â”‚     â”‚   â””â”€â”€ Resize back to original dimensions                 â”‚
â”‚     â””â”€â”€ Stack into 3D volume                                   â”‚
â”‚                                                                 â”‚
â”‚  4. POST-PROCESSING                                             â”‚
â”‚     â”œâ”€â”€ Apply brain mask                                       â”‚
â”‚     â”œâ”€â”€ Map class 3 â†’ label 4 (BraTS convention)              â”‚
â”‚     â””â”€â”€ Generate statistics                                    â”‚
â”‚                                                                 â”‚
â”‚  5. VISUALIZATION                                               â”‚
â”‚     â”œâ”€â”€ Extract voxel coordinates per class                    â”‚
â”‚     â”œâ”€â”€ Subsample for browser performance                      â”‚
â”‚     â””â”€â”€ Return Plotly-compatible 3D scatter data               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Architecture

### Model: ResUNet2D

```
Input (4, 240, 240) â†’ Encoder â†’ Bridge â†’ Decoder â†’ Output (4, 240, 240)
      â†“                                              â†“
   4 channels                                    4 classes
   (FLAIR,T1,T1ce,T2)                     (BG, NC, ED, ET)
```

- **Encoder**: 4 residual blocks with max pooling
- **Bridge**: Deep residual block (512 channels)
- **Decoder**: 4 upsampling blocks with skip connections
- **Output**: 1Ã—1 convolution for pixel-wise classification

### Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI + PyTorch |
| Frontend | React + Tailwind CSS |
| Visualization | Plotly.js |
| Medical Imaging | NiBabel |

---

## ğŸš€ How to Run

### Prerequisites

- Python 3.9+
- Node.js 18+
- CUDA (optional, for GPU acceleration)

### 1. Clone & Setup

```bash
cd Revesion
```

### 2. Backend Setup

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Ensure model file exists
# model_epoch_18.pth should be in the project root
```

### 3. Start Backend

```bash
cd backend
python main.py
```

Or with uvicorn:
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Backend will be available at: `http://localhost:8000`

API docs at: `http://localhost:8000/docs`

### 4. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

Frontend will be available at: `http://localhost:3000`

### 5. Production Build

```bash
# Frontend
cd frontend
npm run build

# Serve with any static server
npx serve dist
```

---

## ğŸ“¡ API Endpoints

### Health Check
```http
GET /health
```

### Run Segmentation
```http
POST /predict
Content-Type: multipart/form-data

flair: <.nii/.nii.gz file>
t1: <.nii/.nii.gz file>
t1ce: <.nii/.nii.gz file>
t2: <.nii/.nii.gz file>
return_rle: true/false
```

**Response:**
```json
{
  "success": true,
  "message": "Segmentation completed successfully",
  "visualization_data": {
    "classes": [
      {
        "class_id": 1,
        "label": "Necrotic Core",
        "color": "red",
        "x": [...],
        "y": [...],
        "z": [...],
        "count": 12345
      }
    ]
  },
  "tumor_volumes": {
    "necrotic_core": 12345,
    "edema": 54321,
    "enhancing_tumor": 6789,
    "total_tumor": 73455
  },
  "volume_shape": [240, 240, 155]
}
```

---

## ğŸ“ Project Structure

```
Revesion/
â”œâ”€â”€ model_epoch_18.pth          # Trained model weights
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ model.py                # ResUNet2D architecture
â”‚   â”œâ”€â”€ preprocessing.py        # NIfTI loading & normalization
â”‚   â””â”€â”€ inference.py            # Inference pipeline
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.js
    â”œâ”€â”€ tailwind.config.js
    â”œâ”€â”€ index.html
    â”‚
    â”œâ”€â”€ public/
    â”‚   â””â”€â”€ brain-icon.svg
    â”‚
    â””â”€â”€ src/
        â”œâ”€â”€ main.jsx
        â”œâ”€â”€ App.jsx
        â”œâ”€â”€ index.css
        â”‚
        â”œâ”€â”€ api/
        â”‚   â””â”€â”€ inference.js
        â”‚
        â””â”€â”€ components/
            â”œâ”€â”€ Header.jsx
            â”œâ”€â”€ FileUpload.jsx
            â”œâ”€â”€ LoadingState.jsx
            â”œâ”€â”€ Visualization3D.jsx
            â””â”€â”€ TumorStats.jsx
```

---

## ğŸ”§ Configuration

### Environment Variables

**Backend:**
```bash
MODEL_PATH=../model_epoch_18.pth  # Path to model weights
DEVICE=auto                        # "auto", "cuda", or "cpu"
```

**Frontend:**
```bash
VITE_API_URL=http://localhost:8000  # Backend API URL
```

---

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Inference Time (GPU) | ~5-10 seconds |
| Inference Time (CPU) | ~30-60 seconds |
| Memory (GPU) | ~2-4 GB |
| Memory (CPU) | ~4-8 GB |

---

## ğŸ† INSTANT-ODC AI Hackathon

This project was developed for the INSTANT-ODC AI Hackathon 2026, focusing on medical AI applications for brain tumor segmentation and visualization.

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¥ Authors

INSTANT-ODC AI Hackathon Team

---

## ğŸ”— References

- [BraTS Challenge](https://www.synapse.org/brats)
- [NiBabel Documentation](https://nipy.org/nibabel/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Plotly.js](https://plotly.com/javascript/)
